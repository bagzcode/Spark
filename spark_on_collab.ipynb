{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark on collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqPGxBntiO/S8G9qdJso8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bagzcode/Spark/blob/main/spark_on_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ViD2J00Phi"
      },
      "source": [
        "# Source Setting up Spark in Collab\n",
        "\n",
        "Source: https://medium.com/analytics-vidhya/getting-started-spark3-0-0-with-google-colab-9796d350d78\n",
        "\n",
        "alternatives: https://stackoverflow.com/questions/55240940/error-while-installing-spark-on-google-colab?rq=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-ZPLrCj0YXL"
      },
      "source": [
        "# Change Java version\n",
        "source: https://stackoverflow.com/questions/58106622/how-to-change-the-java-version-in-google-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AX1Jbnj018R"
      },
      "source": [
        "# example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cRk8YlpGmQ"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRT_mRPiz8vM"
      },
      "source": [
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-oT_C9iz4Pm"
      },
      "source": [
        "!java -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9hqPGn9pVXN"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsiMIyXUpWy3"
      },
      "source": [
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBlHjZJBpZer"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo8aOfYRz1yh"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMeHVadApy3l"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYsihMEGzygr"
      },
      "source": [
        "!rm -r /content/spark-3.0.1-bin-hadoop3.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_3ebF3LprOa"
      },
      "source": [
        "# Check the pyspark version\n",
        "import findspark\n",
        "print(findspark.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_OgkYl_usEb"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Test the spark\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TG9Do0Yu6eZ"
      },
      "source": [
        "# Check the pyspark version\n",
        "import pyspark\n",
        "print(pyspark.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}